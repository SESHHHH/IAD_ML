{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az5lzs1vIY8E"
      },
      "source": [
        "### Машинное обучение\n",
        "## Домашнее задание №3 - Градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xy0wuDRIY8F"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 14 мая 2024, 23:59   \n",
        "**Штраф за опоздание:** -2 балла за каждые сутки\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoiwRo6xIY8G"
      },
      "source": [
        "##  Считаем производные для функций потерь (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsepQdhLIY8G"
      },
      "source": [
        "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
        "\n",
        "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
        "\n",
        "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "где $a(x_i)$ предсказание бустинга на итом объекте.\n",
        "\n",
        "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTmxT4CeIY8G"
      },
      "source": [
        "Ваше решение тут\n",
        "\n",
        "y_hat = a(x) - предсказания предыдущих моделей"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "rjKal7i_cNhm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_grad(y, y_hat, loss):\n",
        "    if loss == 'mse':\n",
        "        return y - y_hat\n",
        "    elif loss == 'exp':\n",
        "        return y * np.exp(-y * y_hat)\n",
        "    elif loss == 'logit':\n",
        "        return y / (1 + np.exp(y * y_hat))"
      ],
      "metadata": {
        "id": "xmaheprtYGN_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8dY42nmIY8G"
      },
      "source": [
        "##  Реализуем градиентный бустинг (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdFRii2WIY8G"
      },
      "source": [
        "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw8C9afsIY8G"
      },
      "source": [
        "Детали реализации:\n",
        "\n",
        "-- должно поддерживаться 3 функции потерь\n",
        "\n",
        "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
        "\n",
        "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
        "\n",
        "-- шаг в бустинге можно не подбирать, можно брать константный\n",
        "\n",
        "-- можно брать разные модели в качестве инициализации бустинга\n",
        "\n",
        "-- должны поддерживаться следующие параметры:\n",
        "\n",
        "а) число итераций\n",
        "б) размер шага\n",
        "в) процент случайных фичей при построении одного дерева\n",
        "д) процент случайных объектов при построении одного дерева\n",
        "е) параметры базового алгоритма (передавайте через **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "NmgK61xrIY8G"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "random_state = 42\n",
        "np.random.seed(random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TWVtVHArIY8H"
      },
      "outputs": [],
      "source": [
        "class MyGradientBoostingClassifier:\n",
        "\n",
        "    def __init__(self, loss='mse', learning_rate=0.1, n_estimators=100, colsample=1.0, subsample=1.0, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        loss -- один из 3 лоссов:\n",
        "        learning_rate -- шаг бустинга\n",
        "        n_estimators -- число итераций\n",
        "        colsample -- процент рандомных признаков при обучении одного алгоритма\n",
        "        subsample -- процент рандомных объектов при обучении одного алгоритма\n",
        "        args, kwargs -- параметры  базовых моделей\n",
        "        \"\"\"\n",
        "        # Ваш код здесь\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.colsample = colsample\n",
        "        self.subsample = subsample\n",
        "        self.base_model_params = kwargs\n",
        "        self.models = []\n",
        "        self.init_model = None\n",
        "\n",
        "    def _calculate_grad(self, y, y_hat):\n",
        "        if self.loss == 'mse':\n",
        "            return y - y_hat\n",
        "        elif self.loss == 'exponential':\n",
        "            return y * np.exp(-y * y_hat)\n",
        "        elif self.loss == 'log_loss':\n",
        "            return y / (1 + np.exp(y * y_hat))\n",
        "\n",
        "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
        "        \"\"\"\n",
        "        X -- объекты для обучения:\n",
        "        y -- таргеты для обучения\n",
        "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
        "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
        "        \"\"\"\n",
        "        # Ваш код здесь\n",
        "        if self.loss == 'log_loss' or self.loss == 'exponential':\n",
        "            y = np.where(y == 0, -1, 1)\n",
        "\n",
        "        if init_model is None:\n",
        "            y_pred = np.zeros(X.shape[0])\n",
        "        else:\n",
        "            self.init_model = init_model\n",
        "            self.init_model.fit(X, y)\n",
        "            y_pred = self.init_model.predict(X)\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            grad = self._calculate_grad(y, y_pred)\n",
        "            model = base_model(**self.base_model_params)\n",
        "\n",
        "            subsamples = np.random.choice(X.shape[0], int(self.subsample * X.shape[0]), replace=False)\n",
        "            colsamples = np.random.choice(X.shape[1], int(self.colsample * X.shape[1]), replace=False)\n",
        "            X_sub = X[subsamples][:, colsamples]\n",
        "            y_sub = grad[subsamples]\n",
        "\n",
        "            model.fit(X_sub, y_sub)\n",
        "\n",
        "            y_pred += self.learning_rate * model.predict(X[:, colsamples])\n",
        "\n",
        "            self.models.append((model, colsamples))\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Ваш код здесь\n",
        "        if self.init_model is None:\n",
        "            y_res = np.zeros(X.shape[0])\n",
        "        else:\n",
        "            y_res = self.init_model.predict(X)\n",
        "\n",
        "        for model, colsamples in self.models:\n",
        "            y_res += self.learning_rate * model.predict(X[:, colsamples])\n",
        "\n",
        "        if self.loss == 'mse':\n",
        "            return np.round(y_res).astype(int)\n",
        "        elif self.loss == 'exponential':\n",
        "            return np.where(y_res > 0, 1, 0)\n",
        "        elif self.loss == 'log_loss':\n",
        "            return (1 / (1 + np.exp(-y_res)) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UG1KgdhDIY8H"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier(loss='mse', max_depth=3)\n",
        "clf = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "81f_UvdyIY8H"
      },
      "outputs": [],
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m9ttzX4VIY8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d291cf8-fddf-410f-fe2d-372b93d1a92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9444444444444444\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "my_clf.fit(X_train, y_train)\n",
        "clf.fit(X_train, y_train)\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m23g8nOdIY8H"
      },
      "source": [
        "## Подбираем параметры (2 балла)\n",
        "\n",
        "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bVRLMGoIY8I"
      },
      "source": [
        "В задании нужно\n",
        "\n",
        "1) Построить график точности в зависимости от числа итераций на валидации.\n",
        "\n",
        "2) Подобрать оптимальные параметры Вашего бустинга на валидации.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zPOnLilqIY8I"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qgTfesqaIY8I",
        "outputId": "f90b06f5-fcaa-4e1b-8d71-39a1959ccb36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ],
      "source": [
        "# Превращаем регрессию в классификацию\n",
        "y = (y > 2.0).astype(int)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "A-XxsrxDIY8I"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.2, n_estimators=100, colsample=0.8, subsample=0.8, max_depth=5)\n",
        "my_clf.fit(X_train, y_train)\n",
        "\n",
        "y_res = np.zeros(X_test.shape[0])\n",
        "test_accuracy = [accuracy_score(y_test, y_res)]\n",
        "for model, colsamples in tqdm(my_clf.models):\n",
        "    y_res += my_clf.learning_rate * model.predict(X_test[:, colsamples])\n",
        "    test_accuracy.append(accuracy_score(y_test, np.where(y_res > 0, 1, 0)))\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntrMRc-iExOK",
        "outputId": "c858c7a3-5c4c-4b00-eec0-38bae7fe6f18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:40<00:00,  1.01s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations_list = range(0, my_clf.n_estimators+1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.title(\"The dependence of Accuracy on iteration\")\n",
        "plt.xlabel(r\"$Number$ $iteration$\")\n",
        "plt.ylabel(r\"Accuracy\")\n",
        "plt.plot(n_iterations_list, test_accuracy, label='Test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "rURcivCpNwub",
        "outputId": "65e52818-10e9-4ca8-d8b0-ca1cb95dd0cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "id": "lKpR9eX_Uz18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "        \"loss\": trial.suggest_categorical(\"loss\", [\"mse\", \"log_loss\", \"exponential\"]),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.5),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 12),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n",
        "        \"colsample\": trial.suggest_float(\"colsample\", 0.5, 1.0),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    gbm = MyGradientBoostingClassifier(random_state=42, **param)\n",
        "\n",
        "    gbm.fit(X_train, y_train)\n",
        "\n",
        "    preds = gbm.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpuijbd1Ry1F",
        "outputId": "9fa8f003-a6d1-4563-8c5c-f852af4d38f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-13 01:24:29,833] A new study created in memory with name: no-name-32eed8a6-4b23-4947-9e50-891a725f740a\n",
            "[I 2024-05-13 01:24:32,002] Trial 0 finished with value: 0.7551679586563308 and parameters: {'loss': 'mse', 'learning_rate': 0.044146931497476, 'max_depth': 1, 'n_estimators': 44, 'colsample': 0.931730423212475, 'subsample': 0.9804217343670527}. Best is trial 0 with value: 0.7551679586563308.\n",
            "[I 2024-05-13 01:24:38,424] Trial 1 finished with value: 0.8869509043927648 and parameters: {'loss': 'mse', 'learning_rate': 0.3794482145141547, 'max_depth': 6, 'n_estimators': 56, 'colsample': 0.864561847986181, 'subsample': 0.9693513836971258}. Best is trial 1 with value: 0.8869509043927648.\n",
            "[I 2024-05-13 01:24:39,445] Trial 2 finished with value: 0.8468992248062015 and parameters: {'loss': 'mse', 'learning_rate': 0.14167498139915116, 'max_depth': 3, 'n_estimators': 23, 'colsample': 0.8610226582538013, 'subsample': 0.7707698141185122}. Best is trial 1 with value: 0.8869509043927648.\n",
            "[I 2024-05-13 01:24:40,172] Trial 3 finished with value: 0.8420542635658915 and parameters: {'loss': 'exponential', 'learning_rate': 0.07598654243369611, 'max_depth': 5, 'n_estimators': 8, 'colsample': 0.7874358533829724, 'subsample': 0.9773419306151523}. Best is trial 1 with value: 0.8869509043927648.\n",
            "[I 2024-05-13 01:24:40,650] Trial 4 finished with value: 0.8546511627906976 and parameters: {'loss': 'exponential', 'learning_rate': 0.09756337763373606, 'max_depth': 7, 'n_estimators': 5, 'colsample': 0.6624265988364579, 'subsample': 0.8886794130984527}. Best is trial 1 with value: 0.8869509043927648.\n",
            "[I 2024-05-13 01:24:53,457] Trial 5 finished with value: 0.8940568475452196 and parameters: {'loss': 'exponential', 'learning_rate': 0.20647515936868022, 'max_depth': 9, 'n_estimators': 79, 'colsample': 0.9537817762381957, 'subsample': 0.8348017936762345}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:24:55,190] Trial 6 finished with value: 0.8682170542635659 and parameters: {'loss': 'mse', 'learning_rate': 0.1936613710748973, 'max_depth': 3, 'n_estimators': 40, 'colsample': 0.9070542686297498, 'subsample': 0.7928911236244157}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:24:59,673] Trial 7 finished with value: 0.8900193798449613 and parameters: {'loss': 'mse', 'learning_rate': 0.2683454031828126, 'max_depth': 6, 'n_estimators': 78, 'colsample': 0.981544551561212, 'subsample': 0.7606912316307781}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:25:02,465] Trial 8 finished with value: 0.8775839793281653 and parameters: {'loss': 'mse', 'learning_rate': 0.034614139417823035, 'max_depth': 6, 'n_estimators': 80, 'colsample': 0.8613018514726691, 'subsample': 0.6438132791935645}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:25:02,595] Trial 9 finished with value: 0.8121770025839793 and parameters: {'loss': 'exponential', 'learning_rate': 0.03698483045849471, 'max_depth': 3, 'n_estimators': 10, 'colsample': 0.5448587971603561, 'subsample': 0.5104084540736333}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:25:07,212] Trial 10 finished with value: 0.8922803617571059 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4859112036565125, 'max_depth': 11, 'n_estimators': 88, 'colsample': 0.719834584862631, 'subsample': 0.6720015929841326}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:25:16,464] Trial 11 finished with value: 0.8908268733850129 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4867677603769217, 'max_depth': 11, 'n_estimators': 100, 'colsample': 0.6700281537338673, 'subsample': 0.655424858702065}. Best is trial 5 with value: 0.8940568475452196.\n",
            "[I 2024-05-13 01:25:22,737] Trial 12 finished with value: 0.898094315245478 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2968296772568889, 'max_depth': 11, 'n_estimators': 100, 'colsample': 0.7412414932019442, 'subsample': 0.6639918791371769}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:27,549] Trial 13 finished with value: 0.8950258397932817 and parameters: {'loss': 'log_loss', 'learning_rate': 0.29761438072348856, 'max_depth': 9, 'n_estimators': 64, 'colsample': 0.7726793867552805, 'subsample': 0.8571384010648236}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:30,248] Trial 14 finished with value: 0.8871124031007752 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3285499878534625, 'max_depth': 9, 'n_estimators': 60, 'colsample': 0.7711712931587369, 'subsample': 0.5749928635452743}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:36,402] Trial 15 finished with value: 0.8950258397932817 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3806068568597326, 'max_depth': 12, 'n_estimators': 100, 'colsample': 0.579380231437066, 'subsample': 0.8711584889814137}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:39,943] Trial 16 finished with value: 0.8938953488372093 and parameters: {'loss': 'log_loss', 'learning_rate': 0.28223598220142376, 'max_depth': 9, 'n_estimators': 64, 'colsample': 0.6311302711280669, 'subsample': 0.7106755166851613}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:41,321] Trial 17 finished with value: 0.8871124031007752 and parameters: {'loss': 'log_loss', 'learning_rate': 0.34266143864039, 'max_depth': 10, 'n_estimators': 32, 'colsample': 0.7249683085492691, 'subsample': 0.5826409259382157}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:45,688] Trial 18 finished with value: 0.8948643410852714 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4164088082423074, 'max_depth': 8, 'n_estimators': 71, 'colsample': 0.809385146582087, 'subsample': 0.8986968738731921}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:50,758] Trial 19 finished with value: 0.8979328165374677 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2223743151602858, 'max_depth': 12, 'n_estimators': 90, 'colsample': 0.5023790107915812, 'subsample': 0.7114858450686051}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:25:55,584] Trial 20 finished with value: 0.8969638242894057 and parameters: {'loss': 'log_loss', 'learning_rate': 0.21999164322999248, 'max_depth': 12, 'n_estimators': 93, 'colsample': 0.5082636143536321, 'subsample': 0.712031417321503}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:00,035] Trial 21 finished with value: 0.8948643410852714 and parameters: {'loss': 'log_loss', 'learning_rate': 0.21415231654466424, 'max_depth': 12, 'n_estimators': 91, 'colsample': 0.518431542278425, 'subsample': 0.7102958168685211}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:04,822] Trial 22 finished with value: 0.8913113695090439 and parameters: {'loss': 'log_loss', 'learning_rate': 0.16632284889149823, 'max_depth': 11, 'n_estimators': 88, 'colsample': 0.5890696235442873, 'subsample': 0.7115714258300756}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:08,825] Trial 23 finished with value: 0.8929263565891473 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2462823559081984, 'max_depth': 12, 'n_estimators': 93, 'colsample': 0.5316844300706451, 'subsample': 0.6140928352039916}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:12,258] Trial 24 finished with value: 0.8932493540051679 and parameters: {'loss': 'log_loss', 'learning_rate': 0.13177930457896575, 'max_depth': 10, 'n_estimators': 74, 'colsample': 0.592572341017332, 'subsample': 0.798713542094803}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:17,687] Trial 25 finished with value: 0.8922803617571059 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2318253624698045, 'max_depth': 12, 'n_estimators': 86, 'colsample': 0.5026545936092964, 'subsample': 0.6938940409486616}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:21,505] Trial 26 finished with value: 0.8898578811369509 and parameters: {'loss': 'log_loss', 'learning_rate': 0.31315943606135577, 'max_depth': 10, 'n_estimators': 97, 'colsample': 0.5576608806072065, 'subsample': 0.620245410928816}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:26,343] Trial 27 finished with value: 0.8959948320413437 and parameters: {'loss': 'log_loss', 'learning_rate': 0.17270620914154453, 'max_depth': 11, 'n_estimators': 84, 'colsample': 0.6346748534255584, 'subsample': 0.7389815457623969}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:28,732] Trial 28 finished with value: 0.8916343669250646 and parameters: {'loss': 'log_loss', 'learning_rate': 0.25003269786092114, 'max_depth': 8, 'n_estimators': 71, 'colsample': 0.6339290229190336, 'subsample': 0.5433708861958786}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:32,646] Trial 29 finished with value: 0.8927648578811369 and parameters: {'loss': 'exponential', 'learning_rate': 0.36027296253488317, 'max_depth': 12, 'n_estimators': 49, 'colsample': 0.7184637646496537, 'subsample': 0.7391046821834789}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:33,333] Trial 30 finished with value: 0.8199289405684754 and parameters: {'loss': 'log_loss', 'learning_rate': 0.44484564529283904, 'max_depth': 1, 'n_estimators': 94, 'colsample': 0.5012715243648301, 'subsample': 0.6234833220380476}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:37,235] Trial 31 finished with value: 0.8848514211886305 and parameters: {'loss': 'log_loss', 'learning_rate': 0.15700564505304293, 'max_depth': 11, 'n_estimators': 83, 'colsample': 0.6219051581104724, 'subsample': 0.7398714127703525}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:42,133] Trial 32 finished with value: 0.8924418604651163 and parameters: {'loss': 'log_loss', 'learning_rate': 0.19382864574833328, 'max_depth': 11, 'n_estimators': 93, 'colsample': 0.6786314663440582, 'subsample': 0.6732521800963481}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:46,838] Trial 33 finished with value: 0.8887273901808785 and parameters: {'loss': 'log_loss', 'learning_rate': 0.11080352871996284, 'max_depth': 10, 'n_estimators': 85, 'colsample': 0.5618947458430557, 'subsample': 0.8059657460285791}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:26:51,373] Trial 34 finished with value: 0.8879198966408268 and parameters: {'loss': 'log_loss', 'learning_rate': 0.17400475726443876, 'max_depth': 11, 'n_estimators': 99, 'colsample': 0.6055058154399537, 'subsample': 0.7370885506716683}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:00,963] Trial 35 finished with value: 0.8806524547803618 and parameters: {'loss': 'mse', 'learning_rate': 0.22438970065703684, 'max_depth': 12, 'n_estimators': 90, 'colsample': 0.8364541558278075, 'subsample': 0.9436397933433915}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:04,304] Trial 36 finished with value: 0.8913113695090439 and parameters: {'loss': 'exponential', 'learning_rate': 0.08447475549822275, 'max_depth': 8, 'n_estimators': 72, 'colsample': 0.6840769416381314, 'subsample': 0.7768205303581204}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:06,035] Trial 37 finished with value: 0.8186369509043928 and parameters: {'loss': 'log_loss', 'learning_rate': 0.005838105208172351, 'max_depth': 4, 'n_estimators': 54, 'colsample': 0.9038436149112495, 'subsample': 0.6840203817271545}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:11,508] Trial 38 finished with value: 0.8793604651162791 and parameters: {'loss': 'mse', 'learning_rate': 0.2708152634498228, 'max_depth': 10, 'n_estimators': 77, 'colsample': 0.653564570147454, 'subsample': 0.820085136996689}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:14,881] Trial 39 finished with value: 0.8835594315245479 and parameters: {'loss': 'log_loss', 'learning_rate': 0.13374389201397474, 'max_depth': 7, 'n_estimators': 83, 'colsample': 0.7022226209704826, 'subsample': 0.760276371546159}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:18,729] Trial 40 finished with value: 0.8938953488372093 and parameters: {'loss': 'exponential', 'learning_rate': 0.18506272359050602, 'max_depth': 11, 'n_estimators': 95, 'colsample': 0.538074054470251, 'subsample': 0.6404584758106866}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:24,550] Trial 41 finished with value: 0.8922803617571059 and parameters: {'loss': 'log_loss', 'learning_rate': 0.29818552928621894, 'max_depth': 9, 'n_estimators': 61, 'colsample': 0.7567152305691976, 'subsample': 0.8643917376764483}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:28,513] Trial 42 finished with value: 0.8916343669250646 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2897565518919248, 'max_depth': 12, 'n_estimators': 45, 'colsample': 0.839174815850084, 'subsample': 0.8392508908568356}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:34,068] Trial 43 finished with value: 0.896156330749354 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2602644991110626, 'max_depth': 10, 'n_estimators': 67, 'colsample': 0.7779434322802717, 'subsample': 0.9957982394823457}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:41,864] Trial 44 finished with value: 0.8901808785529716 and parameters: {'loss': 'mse', 'learning_rate': 0.2541304794909711, 'max_depth': 10, 'n_estimators': 80, 'colsample': 0.8135953458664226, 'subsample': 0.9902778687185121}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:45,867] Trial 45 finished with value: 0.896640826873385 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2010942564598906, 'max_depth': 11, 'n_estimators': 67, 'colsample': 0.747048409767921, 'subsample': 0.7811029459954123}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:47,348] Trial 46 finished with value: 0.8636950904392765 and parameters: {'loss': 'log_loss', 'learning_rate': 0.20632488701031257, 'max_depth': 5, 'n_estimators': 33, 'colsample': 0.7511535365161135, 'subsample': 0.9456015152908025}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:55,105] Trial 47 finished with value: 0.8874354005167958 and parameters: {'loss': 'log_loss', 'learning_rate': 0.23675405329641044, 'max_depth': 12, 'n_estimators': 67, 'colsample': 0.9969793237471118, 'subsample': 0.8951471452807456}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:56,259] Trial 48 finished with value: 0.8801679586563308 and parameters: {'loss': 'exponential', 'learning_rate': 0.3139368280374768, 'max_depth': 11, 'n_estimators': 18, 'colsample': 0.8791018726541869, 'subsample': 0.5914973752724815}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:27:59,201] Trial 49 finished with value: 0.8921188630490956 and parameters: {'loss': 'log_loss', 'learning_rate': 0.26445344847194985, 'max_depth': 10, 'n_estimators': 54, 'colsample': 0.803721529512795, 'subsample': 0.6476445232536648}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:03,999] Trial 50 finished with value: 0.8880813953488372 and parameters: {'loss': 'mse', 'learning_rate': 0.20481555370604837, 'max_depth': 9, 'n_estimators': 66, 'colsample': 0.7858183190844291, 'subsample': 0.7190095303759456}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:08,991] Trial 51 finished with value: 0.8921188630490956 and parameters: {'loss': 'log_loss', 'learning_rate': 0.14730307873912316, 'max_depth': 12, 'n_estimators': 77, 'colsample': 0.6994361431115964, 'subsample': 0.6945039277228309}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:14,375] Trial 52 finished with value: 0.8964793281653747 and parameters: {'loss': 'log_loss', 'learning_rate': 0.18315754210030813, 'max_depth': 11, 'n_estimators': 89, 'colsample': 0.7324989136269252, 'subsample': 0.7725323035840546}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:20,802] Trial 53 finished with value: 0.8942183462532299 and parameters: {'loss': 'log_loss', 'learning_rate': 0.21765997467747378, 'max_depth': 11, 'n_estimators': 90, 'colsample': 0.746186953760999, 'subsample': 0.7781668512853595}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:25,413] Trial 54 finished with value: 0.8913113695090439 and parameters: {'loss': 'log_loss', 'learning_rate': 0.27576059812192466, 'max_depth': 10, 'n_estimators': 97, 'colsample': 0.7273791727379644, 'subsample': 0.6582654265689506}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:36,746] Trial 55 finished with value: 0.8884043927648578 and parameters: {'loss': 'log_loss', 'learning_rate': 0.19555269934004607, 'max_depth': 12, 'n_estimators': 100, 'colsample': 0.9487845961632502, 'subsample': 0.9238784975730607}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:40,953] Trial 56 finished with value: 0.8880813953488372 and parameters: {'loss': 'log_loss', 'learning_rate': 0.11518482514127128, 'max_depth': 11, 'n_estimators': 59, 'colsample': 0.7688277327879484, 'subsample': 0.7630798323671588}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:47,743] Trial 57 finished with value: 0.8917958656330749 and parameters: {'loss': 'log_loss', 'learning_rate': 0.23213124975646676, 'max_depth': 11, 'n_estimators': 88, 'colsample': 0.7359640049172007, 'subsample': 0.8419044897943007}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:53,348] Trial 58 finished with value: 0.8900193798449613 and parameters: {'loss': 'log_loss', 'learning_rate': 0.32529543748372336, 'max_depth': 12, 'n_estimators': 75, 'colsample': 0.7915355528007798, 'subsample': 0.7264697970111862}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:28:55,929] Trial 59 finished with value: 0.8842054263565892 and parameters: {'loss': 'log_loss', 'learning_rate': 0.35395661193425604, 'max_depth': 7, 'n_estimators': 81, 'colsample': 0.5223030696288631, 'subsample': 0.6958220404579452}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:01,108] Trial 60 finished with value: 0.8963178294573644 and parameters: {'loss': 'log_loss', 'learning_rate': 0.258697957635842, 'max_depth': 9, 'n_estimators': 95, 'colsample': 0.7023326806737857, 'subsample': 0.670268095650526}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:06,208] Trial 61 finished with value: 0.8959948320413437 and parameters: {'loss': 'log_loss', 'learning_rate': 0.24701296543787962, 'max_depth': 9, 'n_estimators': 95, 'colsample': 0.7646927931110504, 'subsample': 0.681090853469319}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:12,148] Trial 62 finished with value: 0.895187338501292 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2971278026021714, 'max_depth': 10, 'n_estimators': 92, 'colsample': 0.7060932049295985, 'subsample': 0.7834703827476716}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:16,990] Trial 63 finished with value: 0.8972868217054264 and parameters: {'loss': 'log_loss', 'learning_rate': 0.26065810342025514, 'max_depth': 11, 'n_estimators': 88, 'colsample': 0.6534922502371693, 'subsample': 0.6600780865113144}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:21,110] Trial 64 finished with value: 0.8898578811369509 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2151690743009815, 'max_depth': 11, 'n_estimators': 87, 'colsample': 0.6496989317371833, 'subsample': 0.6025485751261683}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:27,417] Trial 65 finished with value: 0.8935723514211886 and parameters: {'loss': 'log_loss', 'learning_rate': 0.1863062120361335, 'max_depth': 12, 'n_estimators': 97, 'colsample': 0.5619995665491474, 'subsample': 0.6604341439272726}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:32,888] Trial 66 finished with value: 0.8921188630490956 and parameters: {'loss': 'log_loss', 'learning_rate': 0.23726299176258003, 'max_depth': 11, 'n_estimators': 90, 'colsample': 0.6941045765825445, 'subsample': 0.6342544920092495}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:38,779] Trial 67 finished with value: 0.8914728682170543 and parameters: {'loss': 'exponential', 'learning_rate': 0.1601807073988294, 'max_depth': 12, 'n_estimators': 85, 'colsample': 0.6682677779426541, 'subsample': 0.7544697964420911}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:39,911] Trial 68 finished with value: 0.8063630490956072 and parameters: {'loss': 'log_loss', 'learning_rate': 0.28402214790236713, 'max_depth': 1, 'n_estimators': 96, 'colsample': 0.6066879697690175, 'subsample': 0.7049937297674684}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:45,463] Trial 69 finished with value: 0.8942183462532299 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3828912369116872, 'max_depth': 12, 'n_estimators': 92, 'colsample': 0.7427809600644123, 'subsample': 0.6684664989540476}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:49,695] Trial 70 finished with value: 0.8919573643410853 and parameters: {'loss': 'mse', 'learning_rate': 0.1721163297335952, 'max_depth': 8, 'n_estimators': 100, 'colsample': 0.5101265813998205, 'subsample': 0.7326909786289307}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:55,391] Trial 71 finished with value: 0.8929263565891473 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2621790466788157, 'max_depth': 10, 'n_estimators': 82, 'colsample': 0.7259926920112466, 'subsample': 0.817404739638972}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:29:59,696] Trial 72 finished with value: 0.8872739018087855 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3108743992414186, 'max_depth': 10, 'n_estimators': 88, 'colsample': 0.7838713248000176, 'subsample': 0.5719180910486774}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:30:02,817] Trial 73 finished with value: 0.8943798449612403 and parameters: {'loss': 'log_loss', 'learning_rate': 0.22411846921442488, 'max_depth': 11, 'n_estimators': 69, 'colsample': 0.5444148783825163, 'subsample': 0.6857346377363184}. Best is trial 12 with value: 0.898094315245478.\n",
            "[I 2024-05-13 01:30:08,360] Trial 74 finished with value: 0.900032299741602 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2550246201220756, 'max_depth': 11, 'n_estimators': 93, 'colsample': 0.6815641840922588, 'subsample': 0.629950695949161}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:08,454] Trial 75 finished with value: 0.7688953488372093 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2419932323615886, 'max_depth': 11, 'n_estimators': 1, 'colsample': 0.71142706717393, 'subsample': 0.6115219023175495}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:09,692] Trial 76 finished with value: 0.838016795865633 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2760141139225925, 'max_depth': 2, 'n_estimators': 94, 'colsample': 0.6559544052397027, 'subsample': 0.6281004952989218}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:14,470] Trial 77 finished with value: 0.8888888888888888 and parameters: {'loss': 'log_loss', 'learning_rate': 0.1978849920516746, 'max_depth': 9, 'n_estimators': 98, 'colsample': 0.6852420875794683, 'subsample': 0.7500703957067252}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:17,727] Trial 78 finished with value: 0.8955103359173127 and parameters: {'loss': 'log_loss', 'learning_rate': 0.18283416766752145, 'max_depth': 11, 'n_estimators': 91, 'colsample': 0.5754009721814746, 'subsample': 0.5614511407955953}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:22,395] Trial 79 finished with value: 0.8916343669250646 and parameters: {'loss': 'exponential', 'learning_rate': 0.3321833927623245, 'max_depth': 12, 'n_estimators': 86, 'colsample': 0.5253297225993203, 'subsample': 0.645753868979339}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:28,020] Trial 80 finished with value: 0.8950258397932817 and parameters: {'loss': 'log_loss', 'learning_rate': 0.21618577163260533, 'max_depth': 12, 'n_estimators': 94, 'colsample': 0.6722258121915525, 'subsample': 0.7194411085340907}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:33,015] Trial 81 finished with value: 0.8898578811369509 and parameters: {'loss': 'log_loss', 'learning_rate': 0.25886714933661653, 'max_depth': 10, 'n_estimators': 79, 'colsample': 0.7332908757617986, 'subsample': 0.669344536964782}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:36,998] Trial 82 finished with value: 0.8953488372093024 and parameters: {'loss': 'log_loss', 'learning_rate': 0.25544297760735035, 'max_depth': 11, 'n_estimators': 48, 'colsample': 0.7539948410317261, 'subsample': 0.708640257179325}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:38,524] Trial 83 finished with value: 0.8895348837209303 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3024878833427189, 'max_depth': 10, 'n_estimators': 40, 'colsample': 0.7187140403580586, 'subsample': 0.5167210760738059}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:43,432] Trial 84 finished with value: 0.896156330749354 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2282259638159675, 'max_depth': 11, 'n_estimators': 83, 'colsample': 0.8259033543952272, 'subsample': 0.6508504931827729}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:50,850] Trial 85 finished with value: 0.8992248062015504 and parameters: {'loss': 'log_loss', 'learning_rate': 0.28216316479392506, 'max_depth': 11, 'n_estimators': 89, 'colsample': 0.6923323258777526, 'subsample': 0.9648607811529145}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:30:56,637] Trial 86 finished with value: 0.8958333333333334 and parameters: {'loss': 'log_loss', 'learning_rate': 0.291280702769974, 'max_depth': 12, 'n_estimators': 89, 'colsample': 0.6870805124134661, 'subsample': 0.7937431313023835}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:04,848] Trial 87 finished with value: 0.8824289405684754 and parameters: {'loss': 'mse', 'learning_rate': 0.2718182535270003, 'max_depth': 11, 'n_estimators': 97, 'colsample': 0.7117496318257832, 'subsample': 0.9608194676799442}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:09,442] Trial 88 finished with value: 0.8892118863049095 and parameters: {'loss': 'log_loss', 'learning_rate': 0.20733729407899604, 'max_depth': 12, 'n_estimators': 92, 'colsample': 0.697041703572122, 'subsample': 0.5991575737058473}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:13,448] Trial 89 finished with value: 0.8863049095607235 and parameters: {'loss': 'log_loss', 'learning_rate': 0.243999090888742, 'max_depth': 11, 'n_estimators': 85, 'colsample': 0.6182684940330488, 'subsample': 0.6792880929116532}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:19,512] Trial 90 finished with value: 0.8893733850129198 and parameters: {'loss': 'log_loss', 'learning_rate': 0.14667293871476825, 'max_depth': 11, 'n_estimators': 100, 'colsample': 0.6398614473343609, 'subsample': 0.6964551485382023}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:27,996] Trial 91 finished with value: 0.8866279069767442 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2796310848904615, 'max_depth': 10, 'n_estimators': 95, 'colsample': 0.7611685128072458, 'subsample': 0.9949882780205421}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:34,534] Trial 92 finished with value: 0.8937338501291989 and parameters: {'loss': 'log_loss', 'learning_rate': 0.26234763092706637, 'max_depth': 10, 'n_estimators': 76, 'colsample': 0.7767947650889174, 'subsample': 0.9835075792665879}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:41,076] Trial 93 finished with value: 0.8884043927648578 and parameters: {'loss': 'log_loss', 'learning_rate': 0.3076031103878794, 'max_depth': 11, 'n_estimators': 87, 'colsample': 0.7365747622255584, 'subsample': 0.9115684863658985}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:48,001] Trial 94 finished with value: 0.8947028423772609 and parameters: {'loss': 'log_loss', 'learning_rate': 0.24881368573712398, 'max_depth': 11, 'n_estimators': 90, 'colsample': 0.6736106367648428, 'subsample': 0.9678896588811288}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:51,072] Trial 95 finished with value: 0.8916343669250646 and parameters: {'loss': 'log_loss', 'learning_rate': 0.229264835409292, 'max_depth': 10, 'n_estimators': 58, 'colsample': 0.8002579865040017, 'subsample': 0.6168991645468136}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:54,162] Trial 96 finished with value: 0.8814599483204134 and parameters: {'loss': 'log_loss', 'learning_rate': 0.32944150837830366, 'max_depth': 5, 'n_estimators': 98, 'colsample': 0.7168989809028092, 'subsample': 0.6372178563926483}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:31:58,725] Trial 97 finished with value: 0.8863049095607235 and parameters: {'loss': 'log_loss', 'learning_rate': 0.29043606095800206, 'max_depth': 12, 'n_estimators': 64, 'colsample': 0.5116459658829453, 'subsample': 0.9536361987170022}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:32:02,162] Trial 98 finished with value: 0.8880813953488372 and parameters: {'loss': 'exponential', 'learning_rate': 0.20292923526506335, 'max_depth': 6, 'n_estimators': 72, 'colsample': 0.7729256856537527, 'subsample': 0.8842138349608533}. Best is trial 74 with value: 0.900032299741602.\n",
            "[I 2024-05-13 01:32:05,705] Trial 99 finished with value: 0.8921188630490956 and parameters: {'loss': 'log_loss', 'learning_rate': 0.32043079035768085, 'max_depth': 9, 'n_estimators': 80, 'colsample': 0.7482467157931333, 'subsample': 0.6647124299345355}. Best is trial 74 with value: 0.900032299741602.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 100\n",
            "Best trial:\n",
            "  Value: 0.900032299741602\n",
            "  Params: \n",
            "    loss: log_loss\n",
            "    learning_rate: 0.2550246201220756\n",
            "    max_depth: 11\n",
            "    n_estimators: 93\n",
            "    colsample: 0.6815641840922588\n",
            "    subsample: 0.629950695949161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Ответ__: лучший accuracy 0.9 при loss: log_loss, learning_rate: 0.2550246201220756, max_depth: 11, n_estimators: 93, colsample: 0.6815641840922588, subsample: 0.629950695949161"
      ],
      "metadata": {
        "id": "YCbwja-1oMXF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeczuM7QIY8I"
      },
      "source": [
        "## BooBag BagBoo (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kooKXY1-IY8I"
      },
      "source": [
        "Попробуем объединить бустинг и бэгинг. Давайте\n",
        "\n",
        "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
        "\n",
        "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb6tzhKpIY8I"
      },
      "source": [
        "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "kJhkWugFIY8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439d7576-e5c4-40b6-da0f-7aeb2944c935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8829134366925064\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.34419295961063207, colsample=0.7869925539662193, subsample=0.7494709591452795, n_estimators=10, random_state=42)\n",
        "my_clf.fit(X_train, y_train, base_model=RandomForestRegressor)\n",
        "print(accuracy_score(y_test, my_clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "FOs7qAaHIY8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa99d65c-d27e-49be-f092-c173b7c549c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8793604651162791\n"
          ]
        }
      ],
      "source": [
        "def bootstrap(X, y, random_state=None):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    idx = rng.choice(X.shape[0], X.shape[0], replace=True)\n",
        "    return X[idx], y[idx]\n",
        "\n",
        "def fit_multi_boostings(X_train, y_train, n_models=10, **boosting_params):\n",
        "    models = []\n",
        "    for i in range(n_models):\n",
        "        X_boot, y_boot = bootstrap(X_train, y_train, random_state=i)\n",
        "        gb_clf = MyGradientBoostingClassifier(**boosting_params)\n",
        "        gb_clf.fit(X_boot, y_boot)\n",
        "        models.append(gb_clf)\n",
        "    return models\n",
        "\n",
        "def avg_preds(models, X):\n",
        "    preds = np.zeros((X.shape[0], len(models)))\n",
        "    for i, model in enumerate(models):\n",
        "        preds[:, i] = model.predict(X)\n",
        "    return np.round(np.mean(preds, axis=1)).astype(int)\n",
        "\n",
        "models = fit_multi_boostings(X_train, y_train, n_models=10, loss='log_loss', n_estimators=100, learning_rate=0.34419295961063207, max_depth=11)\n",
        "\n",
        "print(accuracy_score(y_test, avg_preds(models, X_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Ответ__: Качество улучшить не удалось. Одной из причин является сложность подбора гиперпараметров: в первом случае необходимо подобрать гиперпараметры для бустинга и для RandomForest. Во втором случае необходимо подобрать гиперпараметры для бустинга и количество N бутстрапированных моделей."
      ],
      "metadata": {
        "id": "Es2ba_lpo0vJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "54rSYc-kIY8J"
      },
      "source": [
        "## Умная инициализация (1 балл)\n",
        "\n",
        "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
        "\n",
        "Получилось ли улучшить качество? Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vzk98AxvIY8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e17b6e-238b-4cfd-ffd5-51f4bccaad2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8998708010335917\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "\n",
        "\n",
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.34419295961063207, colsample=0.7869925539662193, subsample=0.7494709591452795)\n",
        "my_clf.fit(X_train, y_train, init_model=Ridge(alpha=1.0))\n",
        "print(accuracy_score(y_test, my_clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vkaaE9XhIY8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aeb5875-d30f-4d16-dfc7-a97143a6febf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8824289405684754\n"
          ]
        }
      ],
      "source": [
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.34419295961063207, colsample=0.7869925539662193, subsample=0.7494709591452795, max_depth=5, random_state=42)\n",
        "my_clf.fit(X_train, y_train, init_model=Ridge(alpha=1.0, random_state=42))\n",
        "print(accuracy_score(y_test, my_clf.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.34419295961063207, colsample=0.7869925539662193, subsample=0.7494709591452795, max_depth=11, random_state=42)\n",
        "my_clf.fit(X_train, y_train, init_model=Lasso(alpha=0.03, random_state=42))\n",
        "print(accuracy_score(y_test, my_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KfQNsAxs_7X",
        "outputId": "c0440bbe-27e0-41c1-87bb-29b74e90a69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.898094315245478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_clf = MyGradientBoostingClassifier(loss='log_loss', learning_rate=0.34419295961063207, colsample=0.7869925539662193, subsample=0.7494709591452795, max_depth=11, random_state=42)\n",
        "my_clf.fit(X_train, y_train, init_model=RandomForestRegressor(random_state=42))\n",
        "print(accuracy_score(y_test, my_clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT7OP8KOuP8x",
        "outputId": "119150aa-7669-46d1-c235-df67efc5c495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8930878552971576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Ответ__: в целом, получилось улучшить качество благодаря начальной инициализации предсказаний с помощью моделей, а не константным заполнением."
      ],
      "metadata": {
        "id": "8iy-7ZTQuf1g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VingEkOmIY8J"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reNe6KDxIY8J"
      },
      "source": [
        "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2360iGCGIY8J"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3JCrXI-IY8J"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPeACLgdIY8J"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "wva0ZBItIY8J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "sjag35KBIY8J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}